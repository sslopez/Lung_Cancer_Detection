{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "learning_rate = 0.001\n",
    "decay_rate = learning_rate / epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 55, 55, 96)        34944     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 55, 55, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 27, 27, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 27, 27, 256)       614656    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 27, 27, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 384)       885120    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 13, 13, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 13, 13, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 13, 13, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 256)       884992    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              37752832  \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 2002      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 62,422,618\n",
      "Trainable params: 62,401,482\n",
      "Non-trainable params: 21,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model.add(Conv2D(filters=96, input_shape=(227,227,3), kernel_size=(11,11), \n",
    "                 strides=(4,4), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Pooling \n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation before passing it to the next layer\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 4th Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 5th Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Passing it to a dense layer\n",
    "model.add(Flatten())\n",
    "# 1st Dense Layer\n",
    "model.add(Dense(4096, input_shape=(227*227*3,)))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 2nd Dense Layer\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 3rd Dense Layer\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2168 images belonging to 2 classes.\n",
      "Found 541 images belonging to 2 classes.\n",
      "Found 314 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255) \n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                 validation_split=0.20)\n",
    "training_set = train_datagen.flow_from_directory('dataset\\\\traning_set\\\\',\n",
    "                                                target_size = (227,227),\n",
    "                                                batch_size = 32,\n",
    "                                                class_mode = 'categorical',\n",
    "                                                color_mode=\"rgb\",\n",
    "                                                subset='training',\n",
    "                                                shuffle=True,\n",
    "                                                seed=42)\n",
    "valid_set = train_datagen.flow_from_directory('dataset\\\\traning_set\\\\',\n",
    "                                                target_size=(227,227),\n",
    "                                                color_mode=\"rgb\",\n",
    "                                                batch_size=32,\n",
    "                                                class_mode=\"categorical\",\n",
    "                                                subset='validation',\n",
    "                                                shuffle=True,\n",
    "                                                seed=42)\n",
    "\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('dataset\\\\test_set\\\\',\n",
    "                                                target_size = (227,227),\n",
    "                                                batch_size = 1,\n",
    "                                                color_mode=\"rgb\",\n",
    "                                                shuffle=False,\n",
    "                                                class_mode = None,\n",
    "                                                seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.preprocessing.image.DirectoryIterator object at 0x0000024025643460>\n"
     ]
    }
   ],
   "source": [
    "print(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "68/68 [==============================] - 660s 10s/step - loss: 0.8471 - accuracy: 0.5616 - val_loss: 0.7225 - val_accuracy: 0.5139\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.51386, saving model to best_model_1.hdf5\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - 501s 7s/step - loss: 0.7707 - accuracy: 0.6225 - val_loss: 0.7583 - val_accuracy: 0.5139\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.51386\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - 474s 7s/step - loss: 0.7193 - accuracy: 0.6342 - val_loss: 0.7157 - val_accuracy: 0.5545\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.51386 to 0.55453, saving model to best_model_1.hdf5\n",
      "Epoch 4/100\n",
      "68/68 [==============================] - 519s 8s/step - loss: 0.6896 - accuracy: 0.6555 - val_loss: 0.7818 - val_accuracy: 0.5250\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.55453\n",
      "Epoch 5/100\n",
      "68/68 [==============================] - 524s 8s/step - loss: 0.6454 - accuracy: 0.7001 - val_loss: 0.7212 - val_accuracy: 0.5675\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.55453 to 0.56747, saving model to best_model_1.hdf5\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - 508s 7s/step - loss: 0.5920 - accuracy: 0.7148 - val_loss: 0.6970 - val_accuracy: 0.5860\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.56747 to 0.58595, saving model to best_model_1.hdf5\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - 523s 8s/step - loss: 0.5229 - accuracy: 0.7583 - val_loss: 0.7136 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.58595 to 0.60998, saving model to best_model_1.hdf5\n",
      "Epoch 8/100\n",
      "68/68 [==============================] - 567s 8s/step - loss: 0.4505 - accuracy: 0.8166 - val_loss: 1.1090 - val_accuracy: 0.5194\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.60998\n",
      "Epoch 9/100\n",
      "68/68 [==============================] - 565s 8s/step - loss: 0.3453 - accuracy: 0.8515 - val_loss: 0.5996 - val_accuracy: 0.6396\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.60998 to 0.63956, saving model to best_model_1.hdf5\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - 571s 8s/step - loss: 0.2186 - accuracy: 0.9255 - val_loss: 1.0215 - val_accuracy: 0.5619\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.63956\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - 566s 8s/step - loss: 0.1187 - accuracy: 0.9640 - val_loss: 0.4241 - val_accuracy: 0.7579\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.63956 to 0.75786, saving model to best_model_1.hdf5\n",
      "Epoch 12/100\n",
      "68/68 [==============================] - 499s 7s/step - loss: 0.0611 - accuracy: 0.9863 - val_loss: 0.1112 - val_accuracy: 0.9593\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.75786 to 0.95933, saving model to best_model_1.hdf5\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - 533s 8s/step - loss: 0.0493 - accuracy: 0.9923 - val_loss: 0.2571 - val_accuracy: 0.8872\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.95933\n",
      "Epoch 14/100\n",
      "68/68 [==============================] - 344s 5s/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.0286 - val_accuracy: 0.9889\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.95933 to 0.98891, saving model to best_model_1.hdf5\n",
      "Epoch 15/100\n",
      "68/68 [==============================] - 337s 5s/step - loss: 0.0130 - accuracy: 0.9997 - val_loss: 0.0180 - val_accuracy: 0.9963\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.98891 to 0.99630, saving model to best_model_1.hdf5\n",
      "Epoch 16/100\n",
      "68/68 [==============================] - 336s 5s/step - loss: 0.0258 - accuracy: 0.9957 - val_loss: 0.0326 - val_accuracy: 0.9871\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.99630\n",
      "Epoch 17/100\n",
      "68/68 [==============================] - 341s 5s/step - loss: 0.0106 - accuracy: 0.9999 - val_loss: 0.1024 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.99630\n",
      "Epoch 18/100\n",
      "68/68 [==============================] - 344s 5s/step - loss: 0.0136 - accuracy: 0.9975 - val_loss: 0.0262 - val_accuracy: 0.9926\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.99630\n",
      "Epoch 19/100\n",
      "68/68 [==============================] - 338s 5s/step - loss: 0.0117 - accuracy: 0.9989 - val_loss: 0.0193 - val_accuracy: 0.9945\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.99630\n",
      "Epoch 20/100\n",
      "68/68 [==============================] - 339s 5s/step - loss: 0.0102 - accuracy: 0.9985 - val_loss: 0.0103 - val_accuracy: 0.9982\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.99630 to 0.99815, saving model to best_model_1.hdf5\n",
      "Epoch 21/100\n",
      "68/68 [==============================] - 336s 5s/step - loss: 0.0093 - accuracy: 0.9994 - val_loss: 0.0085 - val_accuracy: 0.9982\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.99815\n",
      "Epoch 22/100\n",
      "68/68 [==============================] - 338s 5s/step - loss: 0.0039 - accuracy: 0.9999 - val_loss: 0.0147 - val_accuracy: 0.9945\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.99815\n",
      "Epoch 23/100\n",
      "68/68 [==============================] - 338s 5s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9982\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.99815\n",
      "Epoch 24/100\n",
      "68/68 [==============================] - 351s 5s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9963\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.99815\n",
      "Epoch 25/100\n",
      "68/68 [==============================] - 369s 5s/step - loss: 0.0042 - accuracy: 0.9997 - val_loss: 0.2320 - val_accuracy: 0.8983\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.99815\n",
      "Epoch 26/100\n",
      "68/68 [==============================] - 358s 5s/step - loss: 0.0052 - accuracy: 0.9993 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.99815 to 1.00000, saving model to best_model_1.hdf5\n",
      "Epoch 27/100\n",
      "68/68 [==============================] - 362s 5s/step - loss: 0.0059 - accuracy: 0.9992 - val_loss: 0.4175 - val_accuracy: 0.8688\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 1.00000\n",
      "Epoch 28/100\n",
      "68/68 [==============================] - 351s 5s/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.0081 - val_accuracy: 0.9982\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 1.00000\n",
      "Epoch 29/100\n",
      "68/68 [==============================] - 371s 5s/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 1.00000\n",
      "Epoch 30/100\n",
      "10/68 [===>..........................] - ETA: 4:25 - loss: 0.0037 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-38d07385b843>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     save_best_only=True, mode='max', save_freq=\"epoch\")\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.SGD(lr=learning_rate, momentum=0.9, decay=decay_rate, nesterov=False), metrics = ['accuracy'])\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(\"best_model_1.hdf5\", monitor='val_accuracy', verbose=1,\n",
    "    save_best_only=True, mode='max', save_freq=\"epoch\")\n",
    "\n",
    "history = model.fit(training_set,epochs = epochs,validation_data = valid_set, callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"best_weight1.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-0b220396248c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "print(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a1287fba12f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "#Train and validation accuracy\n",
    "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
    "plt.title('Training and Validation accurarcy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "#Train and validation loss\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99990916, 9.084665e-05]\n",
      "Cancerous\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "categories = [\"Cancerous\",\"Non cancerous\"]\n",
    "from keras.preprocessing import image\n",
    "\n",
    "test_image = image.load_img('dataset\\\\test_set\\\\cancerous\\\\C_1404.jpeg',\n",
    "                            target_size = (227,227))\n",
    "\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.array([test_image], dtype=np.float16) / 255.0\n",
    "result = new_model.predict(test_image)\n",
    "\n",
    "print(list(result[0]))\n",
    "#print('[0.1,0.2,0.5,0.6,0.8,0.1,0.3,0.4]')\n",
    "print(categories[np.argmax(result)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes = predict.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "new_model = load_model('best_model_1.hdf5')\n",
    "#new_model.evaluate(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 24s 76ms/step\n"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TEST=test_set.n//test_set.batch_size\n",
    "test_set.reset()\n",
    "pred=new_model.predict(test_set,\n",
    "steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices=np.argmax(pred,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cancerous': 0, 'non_cancerous': 1}\n",
      "{0: 'cancerous', 1: 'non_cancerous'}\n"
     ]
    }
   ],
   "source": [
    "labels = (training_set.class_indices)\n",
    "print(labels)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "print(labels)\n",
    "predictions = [labels[k] for k in predicted_class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Filename    Predictions\n",
      "0         cancerous\\C_1398.jpeg      cancerous\n",
      "1         cancerous\\C_1399.jpeg      cancerous\n",
      "2         cancerous\\C_1400.jpeg      cancerous\n",
      "3         cancerous\\C_1401.jpeg      cancerous\n",
      "4         cancerous\\C_1402.jpeg      cancerous\n",
      "..                          ...            ...\n",
      "309  non_cancerous\\NC_1469.jpeg  non_cancerous\n",
      "310  non_cancerous\\NC_1470.jpeg  non_cancerous\n",
      "311  non_cancerous\\NC_1471.jpeg  non_cancerous\n",
      "312  non_cancerous\\NC_1472.jpeg  non_cancerous\n",
      "313  non_cancerous\\NC_1473.jpeg  non_cancerous\n",
      "\n",
      "[314 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filenames=test_set.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "print(results)\n",
    "results.to_csv(\"results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-0.82.0-py2.py3-none-any.whl (8.2 MB)\n",
      "Collecting altair>=3.2.0\n",
      "  Downloading altair-4.1.0-py3-none-any.whl (727 kB)\n",
      "Requirement already satisfied: watchdog; platform_system != \"Darwin\" in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from streamlit) (0.10.3)\n",
      "Collecting astor\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from streamlit) (1.19.2)\n",
      "Requirement already satisfied: pandas>=0.21.0 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from streamlit) (1.1.3)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from streamlit) (2.8.1)\n",
      "Collecting pydeck>=0.1.dev5\n",
      "  Downloading pydeck-0.6.2-py2.py3-none-any.whl (4.2 MB)\n",
      "Requirement already satisfied: toml in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from streamlit) (0.10.1)\n",
      "Requirement already satisfied: tornado>=5.0 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from streamlit) (6.0.4)\n",
      "Collecting validators\n",
      "  Downloading validators-0.18.2-py3-none-any.whl (19 kB)\n",
      "Collecting tzlocal\n",
      "  Downloading tzlocal-2.1-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from streamlit) (8.0.1)\n",
      "Collecting base58\n",
      "  Downloading base58-2.1.0-py3-none-any.whl (5.6 kB)\n",
      "Requirement already satisfied: cachetools>=4.0 in c:\\users\\dev-laptop\\appdata\\roaming\\python\\python38\\site-packages (from streamlit) (4.2.1)\n",
      "Collecting blinker\n",
      "  Downloading blinker-1.4.tar.gz (111 kB)\n",
      "Collecting pyarrow; python_version < \"3.9\"\n",
      "  Downloading pyarrow-4.0.0-cp38-cp38-win_amd64.whl (13.3 MB)\n",
      "Requirement already satisfied: click<8.0,>=7.0 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from streamlit) (7.1.2)\n",
      "Requirement already satisfied: protobuf!=3.11,>=3.6.0 in c:\\users\\dev-laptop\\appdata\\roaming\\python\\python38\\site-packages (from streamlit) (3.15.6)\n",
      "Requirement already satisfied: requests in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from streamlit) (2.24.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from streamlit) (20.4)\n",
      "Collecting gitpython\n",
      "  Downloading GitPython-3.1.17-py3-none-any.whl (166 kB)\n",
      "Requirement already satisfied: toolz in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (0.11.1)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (0.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (2.11.2)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (3.2.0)\n",
      "Requirement already satisfied: pathtools>=0.1.1 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from watchdog; platform_system != \"Darwin\"->streamlit) (0.1.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from pandas>=0.21.0->streamlit) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from python-dateutil->streamlit) (1.15.0)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from pydeck>=0.1.dev5->streamlit) (7.5.1)\n",
      "Requirement already satisfied: traitlets>=4.3.2 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from pydeck>=0.1.dev5->streamlit) (5.0.5)\n",
      "Requirement already satisfied: ipykernel>=5.1.2; python_version >= \"3.4\" in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from pydeck>=0.1.dev5->streamlit) (5.3.4)\n",
      "Requirement already satisfied: decorator>=3.4.0 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from validators->streamlit) (4.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from requests->streamlit) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from requests->streamlit) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from requests->streamlit) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from requests->streamlit) (2.10)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from packaging->streamlit) (2.4.7)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from jinja2->altair>=3.2.0->streamlit) (1.1.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from jsonschema->altair>=3.2.0->streamlit) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from jsonschema->altair>=3.2.0->streamlit) (20.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from jsonschema->altair>=3.2.0->streamlit) (50.3.1.post20201107)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.5.1)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (7.19.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.0.8)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from traitlets>=4.3.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (6.1.7)\n",
      "Collecting smmap<5,>=3.0.1\n",
      "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (6.1.4)\n",
      "Requirement already satisfied: pygments in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (2.7.2)\n",
      "Requirement already satisfied: backcall in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.0.8)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.4.4)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.17.1)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (4.6.3)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (19.0.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.9.1)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.0)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (6.0.7)\n",
      "Requirement already satisfied: Send2Trash in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.5.0)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (20.1.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.2.5)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.0)\n",
      "Requirement already satisfied: pywin32>=1.0; sys_platform == \"win32\" in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from jupyter-core->nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (227)\n",
      "Requirement already satisfied: pywinpty>=0.5 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.7)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.3)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n",
      "Requirement already satisfied: testpath in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.4.4)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.6.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
      "Requirement already satisfied: bleach in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.2.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.1.2)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.14.3)\n",
      "Requirement already satisfied: async-generator in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.2)\n",
      "Requirement already satisfied: webencodings in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dev-laptop\\anaconda3\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (2.20)\n",
      "Building wheels for collected packages: blinker\n",
      "  Building wheel for blinker (setup.py): started\n",
      "  Building wheel for blinker (setup.py): finished with status 'done'\n",
      "  Created wheel for blinker: filename=blinker-1.4-py3-none-any.whl size=13454 sha256=a22ba12fb300180ed3179384d616465bc34b028661c3934a48578c6bf0524244\n",
      "  Stored in directory: c:\\users\\dev-laptop\\appdata\\local\\pip\\cache\\wheels\\b7\\a5\\68\\fe632054a5eadd531c7a49d740c50eb6adfbeca822b4eab8d4\n",
      "Successfully built blinker\n",
      "Installing collected packages: altair, astor, pydeck, validators, tzlocal, base58, blinker, pyarrow, smmap, gitdb, gitpython, streamlit\n",
      "Successfully installed altair-4.1.0 astor-0.8.1 base58-2.1.0 blinker-1.4 gitdb-4.0.7 gitpython-3.1.17 pyarrow-4.0.0 pydeck-0.6.2 smmap-4.0.0 streamlit-0.82.0 tzlocal-2.1 validators-0.18.2\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
